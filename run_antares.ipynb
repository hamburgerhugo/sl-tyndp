{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T13:53:18.088850Z",
     "start_time": "2025-09-11T13:53:14.138429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from src.antares_io import (\n",
    "    load_api_config_from_yaml,\n",
    "    get_or_create_study,\n",
    "    update_study_id_in_config,\n",
    "    load_run_config,\n",
    "    load_input_datasets\n",
    ")\n",
    "from src.antares_updater import AntaresStudyUpdater\n",
    "from pommes.io.build_input_dataset import build_input_parameters, read_config_file\n",
    "from pommes.model.data_validation.dataset_check import check_inputs\n",
    "import pandas as pd\n",
    "import antares.craft as ac\n",
    "import datetime\n",
    "\n"
   ],
   "id": "44362366b5d7f123",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T13:53:22.203213Z",
     "start_time": "2025-09-11T13:53:18.529449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CONFIG_LOCAL_PATH = Path(\"config_local.yaml\")\n",
    "CONFIG_RUN_PATH = Path(\"config_run.yaml\")\n",
    "CONFIG_ANTARES_PATH = Path(\"config_antares.yaml\")\n",
    "\n",
    "# Load all configurations\n",
    "local_config = yaml.safe_load(open(CONFIG_LOCAL_PATH))\n",
    "run_config = load_run_config(CONFIG_RUN_PATH)\n",
    "antares_config = yaml.safe_load(open(CONFIG_ANTARES_PATH)) # For UI, etc.\n",
    "\n",
    "# Load all data based on run config\n",
    "datasets = load_input_datasets(run_config)\n",
    "\n",
    "# Load POMMES model parameters (still needed for costs, efficiencies etc.)\n",
    "# TODO This part might also be simplified in the future, likely by loading the pommes netcdf model input file\n",
    "if True:\n",
    "    scenario = run_config['pommes']['scenario']\n",
    "    weather_year = run_config['pommes']['weather_year']\n",
    "\n",
    "    pommes_config = read_config_file(study=scenario, file_path=\"config_pommes.yaml\")\n",
    "    pommes_config[\"coords\"][\"area\"][\"values\"] = run_config['study_parameters']['areas']\n",
    "\n",
    "    ###File pathway update\n",
    "    if scenario==\"DE\":\n",
    "        pommes_config[\"input\"][\"path\"]=\"data/Distributed Energy\"\n",
    "    elif scenario==\"GA\":\n",
    "        pommes_config[\"input\"][\"path\"] = \"data/Global Ambition\"\n",
    "    else:\n",
    "        print(404)\n",
    "        exit()\n",
    "\n",
    "    pommes_config[\"coords\"][\"area\"][\"values\"]=run_config['study_parameters']['areas']\n",
    "    pommes_config[\"coords\"][\"year_op\"][\"values\"] = run_config['study_parameters']['simulation_year']\n",
    "\n",
    "\n",
    "    # pommes_config[\"input\"][\"parameters\"][\"demand\"][\"file\"]=f\"demand_cy{weather_year}.csv\"\n",
    "    # pommes_config[\"input\"][\"parameters\"][\"conversion_availability\"][\"file\"] = f\"availability_cy{weather_year}.csv\"\n",
    "    pommes_config[\"input\"][\"parameters\"][\"conversion_max_yearly_production\"][\"file\"] = f\"conversion_op2_cy{weather_year}.csv\"\n",
    "    pommes_config[\"input\"][\"parameters\"][\"conversion_power_capacity_max\"][\"file\"] = f\"conversion_op2_cy{weather_year}.csv\"\n",
    "    pommes_config[\"input\"][\"parameters\"][\"conversion_power_capacity_min\"][\"file\"] = f\"conversion_op2_cy{weather_year}.csv\"\n",
    "\n",
    "    ####Links adjustment\n",
    "    if pommes_config[\"add_modules\"][\"transport\"] :\n",
    "        areas=pommes_config[\"coords\"][\"area\"][\"values\"]\n",
    "        all_links=pd.read_csv(pommes_config[\"input\"][\"path\"]+\"/transport_link.csv\",sep=\";\").link.unique()\n",
    "        links = []\n",
    "\n",
    "        for link in all_links:\n",
    "            pos = \"\"\n",
    "            i = 0\n",
    "            while pos != \"-\":\n",
    "                pos = link[i]\n",
    "                i += 1\n",
    "            area_from = link[:i - 1]\n",
    "            area_to = link[i:]\n",
    "            if area_to in areas and area_from in areas:\n",
    "                links.append(link)\n",
    "        if len(links) >= 1:\n",
    "            pommes_config[\"coords\"][\"link\"][\"values\"] = links\n",
    "        else:\n",
    "            pommes_config[\"add_modules\"][\"transport\"]=False\n",
    "    print(\"Transport activated:\", pommes_config[\"add_modules\"][\"transport\"])\n",
    "print(\"\\033[1m Building Pommes Model  \\033[0m\")\n",
    "model_parameters = build_input_parameters(pommes_config)\n",
    "model_parameters = check_inputs(model_parameters)"
   ],
   "id": "27a985453d55f41a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading All Input Datasets ---\n",
      "   - INFO: Adding zero-filled data for missing nodes: ['CH00', 'NO00']\n",
      "All datasets loaded successfully.\n",
      "Transport activated: True\n",
      "\u001B[1m Building Pommes Model  \u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamburgerhug\\AppData\\Local\\miniconda3\\envs\\pommes-env\\Lib\\site-packages\\xarray\\core\\duck_array_ops.py:215: RuntimeWarning: invalid value encountered in cast\n",
      "  return data.astype(dtype, **kwargs)\n",
      "WARNING:root:storage_main_resource: Type object converted to str\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T13:53:25.459075Z",
     "start_time": "2025-09-11T13:53:23.124349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "api_config = load_api_config_from_yaml(CONFIG_LOCAL_PATH)\n",
    "study_id = local_config.get(\"antares_study\", {}).get(\"id\")\n",
    "study_name = local_config.get(\"antares_study\", {}).get(\"name\", \"default-sl-study-name\")\n",
    "study = get_or_create_study(api_config=api_config, study_id=study_id, study_name=study_name)\n",
    "if study.service.study_id != study_id:\n",
    "    update_study_id_in_config(CONFIG_LOCAL_PATH, study.service.study_id)"
   ],
   "id": "4a0e55dcc448be69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxy configured for proxy-window-rte-france.com:3128\n",
      "Successfully loaded Antares study 'HH-SL-0.1.1' (ID: f5868019-7181-408f-9679-a7e5879c19f2) from API.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Execute the full update workflow\n",
    "updater.update_areas()\n",
    "updater.update_virtual_areas()\n",
    "updater.update_links()\n",
    "updater.update_thermal_clusters(thermal_tech_map, tech_maps['pommes_to_antares_group'])\n",
    "updater.update_renewable_clusters(tech_maps['vre'], tech_maps['pommes_to_antares_group'], tech_maps['pommes_to_pecd'])\n",
    "updater.update_st_storage(st_storage_map, tech_maps['pommes_to_antares_group'], settings['hurdle_cost'])\n",
    "updater.update_hydro(tech_maps['pommes_to_antares_group'], settings['hydro_policy'])\n",
    "updater.update_run_of_river()\n",
    "updater.update_sector_coupling(tech_maps['p2g'], tech_maps['g2p'], tech_maps['pommes_to_antares_group'])\n",
    "\n",
    "print(\"\\n\\033[1mANTARES study update complete!\\033[0m\")"
   ],
   "id": "4f0bed4699bd5989"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T13:54:02.107088Z",
     "start_time": "2025-09-11T13:54:01.904467Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AntaresStudyUpdater initialized for study 'HH-SL-0.1.1' and year 2040.\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": [
    "\n",
    "# --- 1. Initialize the Updater ---\n",
    "\n",
    "# This single object now holds all the necessary data and the study itself.\n",
    "updater = AntaresStudyUpdater(\n",
    "    study=study,\n",
    "    model_parameters=model_parameters,\n",
    "    pommes_output=datasets[\"pommes_output\"],\n",
    "    antares_config=antares_config,\n",
    "    load_el=datasets[\"load_el\"],\n",
    "    load_h2=datasets[\"load_h2\"],\n",
    "    pecd=datasets[\"pecd\"],\n",
    "    hydro_data=datasets[\"hydro_data\"],\n",
    "    areas=run_config['study_parameters']['areas'],\n",
    "    weather_years=list(range(\n",
    "        run_config['study_parameters']['weather_years']['start'],\n",
    "        run_config['study_parameters']['weather_years']['end'] + 1\n",
    "    )),\n",
    "    year=run_config['study_parameters']['simulation_year']\n",
    ")\n",
    "\n",
    "# Get all settings and mappings directly from the loaded config\n",
    "tech_maps = run_config['technology_mappings']\n",
    "settings = run_config['model_settings']\n",
    "\n",
    "\n",
    "thermal_tech_map = {'electricity': tech_maps['thermal_el'], 'hydrogen': tech_maps['thermal_h2']}\n",
    "st_storage_map = {'electricity': tech_maps['st_storage_el'], 'hydrogen': tech_maps['st_storage_h2']}"
   ],
   "id": "f84c17decfa26a39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T14:29:06.185207Z",
     "start_time": "2025-09-11T14:29:06.029177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "study.get_outputs()\n",
    "study.get_output()"
   ],
   "id": "b9cfbb8b34d1bf96",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'20250911-1451eco': <antares.craft.model.output.Output at 0x2e637ab8490>,\n",
       "              '20250911-1523eco': <antares.craft.model.output.Output at 0x2e637ab85d0>,\n",
       "              '20250911-1556eco': <antares.craft.model.output.Output at 0x2e637ad0ad0>})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T13:59:22.098419Z",
     "start_time": "2025-09-11T13:54:49.484339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "api_config = load_api_config_from_yaml(CONFIG_LOCAL_PATH)\n",
    "study_id = local_config.get(\"antares_study\", {}).get(\"id\")\n",
    "study_name = local_config.get(\"antares_study\", {}).get(\"name\", \"default-sl-study-name\")\n",
    "study = get_or_create_study(api_config=api_config, study_id=study_id, study_name=study_name)\n",
    "if study.service.study_id != study_id:\n",
    "    update_study_id_in_config(CONFIG_LOCAL_PATH, study.service.study_id)\n",
    "\n",
    "import antares.craft as ac\n",
    "# TEST HYDRO_FAST, 34 WY, PRESOLVE -------  LAST RUN -------------  // TESTER SIRIUS\n",
    "solver = \"xpress\"\n",
    "if solver == \"xpress\":\n",
    "    solver = ac.Solver.XPRESS # sirius, xpress, gurobi (in 9.3)\n",
    "nb_cpu = run_config['study_parameters']['weather_years']['end'] - run_config['study_parameters']['weather_years']['start'] +1\n",
    "simulation_parameters = ac.AntaresSimulationParameters(\n",
    "    solver=solver,\n",
    "    nb_cpu=nb_cpu,\n",
    "    presolve=True,\n",
    ")\n",
    "print(f\"start - {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "job = study.run_antares_simulation(simulation_parameters)\n",
    "study.wait_job_completion(job)\n",
    "print(f\"end - {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ],
   "id": "49d4f921b3614a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxy configured for proxy-window-rte-france.com:3128\n",
      "Successfully loaded Antares study 'HH-SL-0.1.1' (ID: f5868019-7181-408f-9679-a7e5879c19f2) from API.\n",
      "start - 2025-09-11 15:54:51\n",
      "end - 2025-09-11 15:59:22\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T13:39:36.572918Z",
     "start_time": "2025-09-11T13:39:36.411016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "simulation_parameters.to_api()\n",
    "ac.Solver.XPRESS.value"
   ],
   "id": "ddb25163a17f09",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xpress'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T12:48:58.488136Z",
     "start_time": "2025-09-11T12:48:58.081121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import antares.craft as ac\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# --- 1. Define Simulation Parameters ---\n",
    "nb_cpu = run_config['study_parameters']['weather_years']['end'] - run_config['study_parameters']['weather_years']['start'] + 1\n",
    "solver_name_for_api = \"xpress\"  # <-- CRITICAL CHANGE: Use lowercase for AntaREST compatibility\n",
    "\n",
    "# --- 2. Manually Construct the API Payload with the Corrected Solver String ---\n",
    "print(f\"--- Preparing Simulation (Testing lowercase solver: '{solver_name_for_api}') ---\")\n",
    "\n",
    "# Start with the base parameter object\n",
    "base_parameters = ac.AntaresSimulationParameters(nb_cpu=nb_cpu)\n",
    "api_payload = base_parameters.to_api()\n",
    "\n",
    "# This is the crucial step: Add the 'other_options' key with the lowercase value.\n",
    "api_payload['other_options'] = solver_name_for_api\n",
    "print(f\"Final API payload being sent: {api_payload}\")\n",
    "\n",
    "\n",
    "# --- 4. Launch Simulation and Wait ---\n",
    "job_id = None\n",
    "output_id = None\n",
    "try:\n",
    "    print(f\"Submitting job at: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    # Use the service layer to send our custom payload\n",
    "    url = f\"{study.service._base_url}/launcher/run/{study_id}\"\n",
    "    response = study.service._wrapper.post(url, json=api_payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    job_id = response.json()[\"job_id\"]\n",
    "    print(f\"Job '{job_id}' submitted successfully. Now waiting for completion...\")\n",
    "\n",
    "    while True:\n",
    "        job_status_obj = study.get_job_status(job_id)\n",
    "        current_status = job_status_obj.status\n",
    "        print(f\"  Current job status: {current_status.value}...\")\n",
    "        if current_status in [ac.JobStatus.SUCCESS, ac.JobStatus.FAILED]:\n",
    "            break\n",
    "        time.sleep(15)\n",
    "\n",
    "    print(f\"Job completed at: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    # --- 5. Check Final Status and Get Results ---\n",
    "    final_job_status = study.get_job_status(job_id)\n",
    "\n",
    "    if final_job_status.status == ac.JobStatus.SUCCESS:\n",
    "        output_id = final_job_status.output_id\n",
    "        print(\"\\n\\033[1mSimulation successful!\\033[0m\")\n",
    "        print(f\"Output ID: {output_id}\")\n",
    "        run_config['last_output_id'] = output_id\n",
    "    else:\n",
    "        print(f\"\\n\\033[1mError: Simulation failed with status '{final_job_status.status.value}'.\\033[0m\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "# --- 6. (Optional) Fetch Logs on Failure ---\n",
    "if output_id is None and job_id:\n",
    "    try:\n",
    "        logs = study.get_job_logs(job_id)\n",
    "        print(\"--- SIMULATION LOGS ---\\n\", logs.get('both', 'No logs available.'), \"\\n--- END OF LOGS ---\")\n",
    "    except Exception as log_e:\n",
    "        print(f\"Could not retrieve job logs: {log_e}\")"
   ],
   "id": "3eaffcc3f82d913e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing Simulation (Testing lowercase solver: 'xpress') ---\n",
      "Final API payload being sent: {'nb_cpu': 34, 'auto_unzip': True, 'other_options': 'xpress'}\n",
      "Deleting previous simulation outputs...\n",
      "Submitting job at: 2025-09-11 14:48:58\n",
      "Job '0002ed20-34ac-4b40-9288-742846cb5414' submitted successfully. Now waiting for completion...\n",
      "An unexpected error occurred: 'Study' object has no attribute 'get_job_status'\n",
      "Could not retrieve job logs: 'Study' object has no attribute 'get_job_logs'\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#TODO UNFEASIBILITY WITH ACCURATE MODE (not sure) LAUNCHED BY THE API",
   "id": "4b58772d02bf9ebe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5f37b557d5915c49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#TODO study options, e.g. hydro accurate ...\n",
    "updater.study.set_playlist()\n",
    "updater.study.set_thematic_trimming()\n",
    "updater.study.set_scenario_builder()\n",
    "updater.study.generate_thermal_timeseries()\n"
   ],
   "id": "e63af30f288c86c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3ca4125075aacf82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "#TODO: use a seed for the base study, variant for each year 2030, 2040, 2050\n",
    "updater.study.create_variant()\n",
    "updater.study.delete()\n",
    "updater.study.run_antares_simulation()\n"
   ],
   "id": "b92bf6369c731f0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Add a cell to run study\n",
    "# TODO: Add a cell to read results\n",
    "# TODO: Filter outputs saved\n",
    "# TODO delete outputs\n",
    "\n",
    "# TODO: Add h2 import\n",
    "# TODO: add salt_cavern\n",
    "# todo forward availability for nuke / old_nuke conversion_tech\n",
    "# todo forward mustrun for nuke / old_nuke conversion_tech  -->> Defined per cluster in antares, not possible here\n",
    "# TODO:\n",
    "# TODO: add parameters not yet implemented\n",
    "\n",
    "# TODO: propper logger\n",
    "# TODO: skip part of the processes that are not necessary  after the study has been initialised (e.g. it 3, no need to send VRES load_factor (defined in % and so normalised) again, as they are already properly defined and will not be affected by invenstment changes, likely the same for hydro as they can't be invested\n",
    "# TODO: check if it works for 2030, 2040 and 2050\n",
    "# TODO: read directly pommes inputs file\n"
   ],
   "id": "b9dc47a6d7930441"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Antares study ID:\n",
    "* fd9aef41-4386-455d-9d69-39123b9d1360 # Old one\n",
    "* d6f3cd34-fec2-4844-8185-f5ed78ebddb7 # ID study creation issue due to no output folder\n",
    "* d1677c86-4938-49bb-b4be-acd9afa3fb65"
   ],
   "id": "209ce7aa2f352e9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
